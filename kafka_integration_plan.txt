Kafka Integration Plan – Interview Reference
============================================

1. 引入目标
-----------
当前下单、缓存刷新、通知推送等逻辑仍是同步串行执行，高峰时接口耗时长、服务耦合度高。引入 Kafka 作为事件总线，解决以下问题：

- **削峰填谷**：订单创建等热点操作先写入消息队列，由消费者异步处理（缓存刷新、通知提醒），缩短主流程响应时间。
- **服务解耦**：订单、通知、统计、推荐等模块通过事件交互，降低直接依赖，方便独立扩展与部署。
- **可追溯性**：Kafka 自带日志持久化，支持重放与补偿处理，为风控、审计、BI 提供数据来源。

2. 规划的 Topic 与事件
-----------------------
| Topic            | 事件类型                | 生产者            | 主要消费者             |
|------------------|------------------------|-------------------|------------------------|
| `order-events`   | `ORDER_CREATED`, `ORDER_STATUS_CHANGED` | 订单服务 | 通知服务、缓存刷新、统计服务 |
| `goods-events`   | `GOODS_VIEWED`, `GOODS_UPDATED`         | 商品服务 | 热度排行、搜索索引、推荐服务 |
| `chat-events`    | `CHAT_MESSAGE_CREATED`                  | 聊天服务 | 推送服务、审计日志          |

- 事件格式：统一 JSON（或 Avro）结构，包含 `eventType`, `timestamp`, `payload`, `version` 等字段，便于扩展。
- key 策略：使用业务主键（如 `orderId`、`goodsId`、`messageId`）保证同一实体的事件落在同一分区，以保持顺序。

3. 生产者（Producer）改造
--------------------------
1. 抽象 `EventPublisher` 组件，封装 Kafka Producer 配置（序列化器、重试次数、acks 等）。
2. 在业务逻辑成功提交数据库事务后发布事件，例如：
   - 订单创建成功 → 发布 `ORDER_CREATED`；
   - 商品审核通过 → 发布 `GOODS_UPDATED`；
   - 聊天消息保存成功 → 发布 `CHAT_MESSAGE_CREATED`。
3. 失败处理：启用 Kafka Producer 重试；记录发送结果，必要时补偿（人工或自动重放）。

4. 消费者（Consumer）设计
-------------------------
- **通知服务**：订阅 `order-events` / `chat-events`，向买卖双方发送站内信、邮件或 WebSocket 推送。
- **缓存刷新服务**：订阅 `goods-events` / `order-events`，异步更新 Redis 热度和排行榜。
- **统计/BI 服务**：消费所有业务事件，汇总行为数据，提供报表与实时监控。
- **搜索索引服务（如接 Elasticsearch）**：收到 `GOODS_UPDATED` 后更新商品搜索索引。

消费策略：
- 创建独立的 Consumer Group，支持水平扩展。
- 消费代码需要幂等（重复消息不产生副作用），可借助 Redis Set 或数据库唯一键判断是否处理过。
- 对于处理失败，采用 Spring Kafka 的 `SeekToCurrentErrorHandler` 或自定义重试策略，实在无法处理则写入死信队列。

5. 运维与监控
--------------
- **部署**：开发环境可用 Docker Compose，生产环境建议使用高可用集群（3+ broker），并启用认证/ACL。
- **监控**：接入 Prometheus + Grafana，关注生产/消费速率、延迟、失败次数、Lag；也可使用 Kafka Manager/Confluent Control Center。
- **日志**：按事件 ID、类型记录消费日志，方便排查与追踪。
- **Schema 管理**：如后续采用 Avro，可引入 Schema Registry 统一管理消息格式。

6. 与现有系统的协作
--------------------
- Redis：依旧负责热点缓存、排行榜、限流。Kafka 事件消费者会据此刷新/写入 Redis，实现异步化。
- MinIO、数据库等逻辑保持不变，由事件异步触发相关操作（如清理文件、调整库存）。
- 若后续引入其他中间件（搜索、配置中心），可以通过 Kafka 事件进行同步，不会产生冲突。

7. 实施步骤总结
-----------------
1. 落地 Kafka 集群并配置基础 Topic。
2. 抽象统一事件模型与发布组件，完成订单、商品、聊天等生产端改造。
3. 编写消费者服务，按功能拆模块，处理幂等、补偿与监控。
4. 更新架构文档与 `SETUP_GUIDE`，记录部署流程与调试方法。
5. 编写集成测试（可使用 Testcontainers Kafka）验证生产/消费链路。

— 以上内容可作为面试时的讲稿/文档参考 —
